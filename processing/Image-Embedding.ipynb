{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"image embeddings\"\n",
    "\n",
    "In order to use the images to learn captionings, we need to combine the power of Convolutional Neural Networs (CNN) and Recurrent Neural Networks (RNN)\n",
    "\n",
    "It's not immediately clear how to do this. But, a common technique is to use a pretrained deep neural network, such as VGG16 or Inception, run said network on the training images, and extract the activations at a given layer to produce one vector per image. This vector can be thought of as an \"image embedding.\"\n",
    "\n",
    "The rationale is that deep networks like VGG16, which perform well on the ImageNet classification task, are capable of extracting very complex features from an image. Thus, if we take off the last couple of layers (which are responsible for the classification of an image to one of the ImageNet classes), then the vector we get will encode interesting features in our images. \n",
    "\n",
    "Here, I extract image embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize an abridged VGG16 model\n",
    "\n",
    "First, I'll take a pre-trained VGG16 model, trained on the ImageNet dataset. Then I'll take off the last two layers, so that I can keep just the feature extracting mechanism and remove the part that is responsible for the ImageNet classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: images: File exists\r\n"
     ]
    }
   ],
   "source": [
    "mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, \"images/vgg16.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take off two layers from the model\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 117,479,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions for feature extraction\n",
    "\n",
    "Given the name of a csv file, which is assumed to have a column *photo_id*, create and return a dictionary of {image_id : [extracted features]} pairs. The extracted features will be vectors of dimension 4096. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_photo_features(list_file):\n",
    "    # read the list of photos to read\n",
    "    photo_list = pd.read_csv(open(list_file,'r'), encoding='utf-8', engine='c')['photo_id']\n",
    "    # accumulate the extracted featues in {photo_id: [..features..]} pairs\n",
    "    features = dict()\n",
    "    i = 0\n",
    "    starttime = time.time()\n",
    "    for photo in photo_list:\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processed %d photos in %f seconds\" % (i, starttime - time.time()))\n",
    "        i += 1\n",
    "        # crate a file name\n",
    "        fname = \"../data/yelp_photos/photos/%s.jpg\" % (photo)\n",
    "        # open the photo\n",
    "        try: \n",
    "            img = load_img(fname, target_size = (224,224))\n",
    "            # preprocess to be compatible with VGG16 network\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            img = preprocess_input(img)\n",
    "            # run the abridged VGG16 model to extract the features\n",
    "            feat = model.predict(img, verbose=0)\n",
    "            # add to feature dictionary\n",
    "            features[photo] = feat\n",
    "        except:\n",
    "            continue\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract training, validation, and playground features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 photos in -0.001062 seconds\n",
      "Processed 500 photos in -274.687827 seconds\n",
      "Processed 1000 photos in -549.285257 seconds\n",
      "Processed 1500 photos in -823.234057 seconds\n",
      "Processed 2000 photos in -1097.450804 seconds\n",
      "Processed 2500 photos in -1372.238161 seconds\n",
      "Processed 3000 photos in -1648.023965 seconds\n",
      "Processed 3500 photos in -1926.930349 seconds\n",
      "Processed 4000 photos in -2206.056092 seconds\n",
      "Processed 4500 photos in -2485.632816 seconds\n",
      "Processed 5000 photos in -2765.037676 seconds\n",
      "Processed 5500 photos in -3044.301722 seconds\n",
      "Processed 6000 photos in -3318.817983 seconds\n",
      "Processed 6500 photos in -3593.101361 seconds\n",
      "Processed 7000 photos in -3868.167157 seconds\n",
      "Processed 7500 photos in -4142.990487 seconds\n",
      "Processed 8000 photos in -4417.113142 seconds\n",
      "Processed 8500 photos in -4691.361947 seconds\n",
      "Processed 9000 photos in -4966.055367 seconds\n",
      "Processed 9500 photos in -5240.475892 seconds\n",
      "Processed 10000 photos in -5514.582549 seconds\n",
      "Processed 10500 photos in -5788.835517 seconds\n",
      "Processed 11000 photos in -6064.972921 seconds\n",
      "Processed 11500 photos in -6353.805617 seconds\n",
      "Processed 12000 photos in -6639.851078 seconds\n",
      "Processed 12500 photos in -6924.975233 seconds\n",
      "Processed 13000 photos in -7211.497032 seconds\n",
      "Processed 13500 photos in -7499.548005 seconds\n",
      "Processed 14000 photos in -7787.493514 seconds\n",
      "Processed 14500 photos in -8074.857981 seconds\n",
      "Processed 15000 photos in -8360.614372 seconds\n",
      "Processed 15500 photos in -8647.737875 seconds\n",
      "Processed 16000 photos in -8934.452989 seconds\n",
      "Processed 16500 photos in -9220.453161 seconds\n",
      "Processed 17000 photos in -9507.521960 seconds\n",
      "Processed 17500 photos in -9795.017431 seconds\n",
      "Processed 18000 photos in -10083.409914 seconds\n",
      "Processed 18500 photos in -10370.316920 seconds\n",
      "Processed 19000 photos in -10656.276091 seconds\n",
      "Processed 19500 photos in -10943.823901 seconds\n",
      "Processed 20000 photos in -11229.764105 seconds\n",
      "Processed 20500 photos in -11515.720150 seconds\n",
      "Processed 21000 photos in -11801.904321 seconds\n",
      "Processed 21500 photos in -12087.683204 seconds\n",
      "Processed 22000 photos in -12373.959327 seconds\n",
      "Processed 22500 photos in -12660.323593 seconds\n",
      "Processed 23000 photos in -12946.234529 seconds\n",
      "Processed 23500 photos in -13233.164501 seconds\n",
      "Processed 24000 photos in -13519.374475 seconds\n",
      "Processed 24500 photos in -13806.933938 seconds\n",
      "Processed 25000 photos in -14093.280183 seconds\n",
      "Processed 25500 photos in -14379.569898 seconds\n",
      "Processed 26000 photos in -14667.600254 seconds\n",
      "Processed 26500 photos in -14954.377101 seconds\n",
      "Processed 27000 photos in -15241.067763 seconds\n",
      "Processed 27500 photos in -15526.442946 seconds\n",
      "Processed 28000 photos in -15812.331213 seconds\n",
      "Processed 28500 photos in -16097.993093 seconds\n",
      "Processed 29000 photos in -16383.773070 seconds\n",
      "Processed 29500 photos in -16669.075711 seconds\n",
      "Processed 30000 photos in -16955.460851 seconds\n",
      "Processed 30500 photos in -17241.549299 seconds\n",
      "Processed 31000 photos in -17526.763105 seconds\n",
      "Processed 31500 photos in -17812.789017 seconds\n",
      "Processed 32000 photos in -18098.966114 seconds\n",
      "Processed 32500 photos in -18384.637977 seconds\n",
      "Processed 33000 photos in -18670.921484 seconds\n",
      "Processed 33500 photos in -18956.463079 seconds\n",
      "Processed 34000 photos in -19242.330035 seconds\n",
      "Processed 34500 photos in -19527.728546 seconds\n",
      "Processed 35000 photos in -19812.474906 seconds\n",
      "Processed 35500 photos in -20097.097204 seconds\n",
      "Processed 36000 photos in -20392.969925 seconds\n",
      "Processed 36500 photos in -20678.518095 seconds\n",
      "Processed 37000 photos in -20967.223944 seconds\n",
      "Processed 37500 photos in -21254.425372 seconds\n",
      "Processed 38000 photos in -21541.123217 seconds\n",
      "Processed 38500 photos in -21829.542880 seconds\n",
      "Processed 39000 photos in -22117.619156 seconds\n",
      "Processed 39500 photos in -22404.760127 seconds\n",
      "Processed 40000 photos in -22696.360716 seconds\n",
      "Processed 40500 photos in -22983.480011 seconds\n",
      "Processed 41000 photos in -23269.406503 seconds\n",
      "Processed 41500 photos in -23556.557129 seconds\n",
      "Processed 42000 photos in -23841.396001 seconds\n",
      "Processed 42500 photos in -24129.340874 seconds\n",
      "Processed 43000 photos in -24416.935462 seconds\n",
      "Processed 43500 photos in -24703.681384 seconds\n",
      "Processed 44000 photos in -24992.880483 seconds\n",
      "Processed 44500 photos in -25284.028664 seconds\n",
      "Processed 45000 photos in -25576.125047 seconds\n",
      "Processed 45500 photos in -25868.038068 seconds\n",
      "Processed 46000 photos in -26159.625154 seconds\n",
      "Processed 46500 photos in -26450.980567 seconds\n",
      "Processed 47000 photos in -26741.824526 seconds\n",
      "Processed 47500 photos in -27032.982738 seconds\n",
      "Processed 48000 photos in -27330.868488 seconds\n",
      "Processed 48500 photos in -27622.898976 seconds\n",
      "Processed 49000 photos in -27915.246334 seconds\n",
      "Processed 49500 photos in -28207.164053 seconds\n",
      "Processed 50000 photos in -28500.446244 seconds\n",
      "Processed 50500 photos in -28815.583104 seconds\n",
      "Processed 51000 photos in -29147.067403 seconds\n",
      "Processed 51500 photos in -29516.352500 seconds\n",
      "Processed 52000 photos in -29808.208537 seconds\n",
      "Processed 52500 photos in -30100.745933 seconds\n",
      "Processed 53000 photos in -30392.097717 seconds\n",
      "Processed 53500 photos in -30686.498308 seconds\n",
      "Processed 54000 photos in -30978.698409 seconds\n",
      "Processed 54500 photos in -31271.288643 seconds\n",
      "Processed 55000 photos in -31563.344364 seconds\n",
      "Processed 55500 photos in -31854.796192 seconds\n",
      "Processed 56000 photos in -32146.664110 seconds\n",
      "Processed 56500 photos in -32438.027403 seconds\n",
      "Processed 57000 photos in -32731.063034 seconds\n",
      "Processed 57500 photos in -33023.122308 seconds\n",
      "Processed 58000 photos in -33315.174013 seconds\n",
      "Processed 58500 photos in -33607.678826 seconds\n",
      "Processed 59000 photos in -33899.917267 seconds\n",
      "Processed 59500 photos in -34193.108542 seconds\n",
      "Processed 60000 photos in -34485.547240 seconds\n",
      "Processed 60500 photos in -34778.074516 seconds\n",
      "Processed 61000 photos in -35070.273245 seconds\n",
      "Processed 61500 photos in -35363.470089 seconds\n",
      "Processed 62000 photos in -35656.144002 seconds\n",
      "Processed 62500 photos in -35948.655411 seconds\n",
      "Processed 63000 photos in -36242.343098 seconds\n",
      "Processed 63500 photos in -36535.082403 seconds\n",
      "Processed 64000 photos in -36827.955505 seconds\n",
      "Processed 64500 photos in -37120.816540 seconds\n",
      "Processed 65000 photos in -37413.549687 seconds\n",
      "Processed 65500 photos in -37706.285681 seconds\n",
      "Processed 66000 photos in -37998.711196 seconds\n",
      "Processed 66500 photos in -38291.344525 seconds\n",
      "Processed 67000 photos in -38583.815956 seconds\n",
      "Processed 67500 photos in -38882.319740 seconds\n",
      "Processed 68000 photos in -39175.210113 seconds\n",
      "Processed 68500 photos in -39468.278593 seconds\n",
      "Processed 69000 photos in -39762.382424 seconds\n",
      "Processed 69500 photos in -40055.070017 seconds\n",
      "Processed 70000 photos in -40347.934607 seconds\n",
      "Processed 70500 photos in -40640.520074 seconds\n",
      "Processed 71000 photos in -40935.712736 seconds\n",
      "Processed 71500 photos in -41228.768000 seconds\n",
      "Processed 72000 photos in -41538.739985 seconds\n",
      "Processed 72500 photos in -41889.638437 seconds\n",
      "Processed 73000 photos in -42182.306461 seconds\n",
      "Processed 73500 photos in -42485.526843 seconds\n",
      "Processed 74000 photos in -42778.030267 seconds\n",
      "Processed 74500 photos in -43070.049140 seconds\n",
      "Processed 75000 photos in -43362.822261 seconds\n",
      "Processed 75500 photos in -43655.365711 seconds\n",
      "Processed 76000 photos in -43947.840046 seconds\n",
      "Processed 76500 photos in -44240.123486 seconds\n",
      "Processed 77000 photos in -44532.464978 seconds\n",
      "Processed 77500 photos in -44825.240440 seconds\n",
      "Processed 78000 photos in -45117.933177 seconds\n",
      "Processed 78500 photos in -45410.531770 seconds\n",
      "Processed 79000 photos in -45703.093798 seconds\n",
      "Processed 79500 photos in -45996.264380 seconds\n",
      "Processed 80000 photos in -46288.763646 seconds\n",
      "Processed 80500 photos in -46581.873395 seconds\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_photo_features(\"../data/split_lists/train_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 photos in -0.000293 seconds\n",
      "Processed 500 photos in -288.742708 seconds\n",
      "Processed 1000 photos in -574.111870 seconds\n",
      "Processed 1500 photos in -860.867980 seconds\n",
      "Processed 2000 photos in -1145.466990 seconds\n",
      "Processed 2500 photos in -1428.325070 seconds\n",
      "Processed 3000 photos in -1712.472551 seconds\n",
      "Processed 3500 photos in -1996.174122 seconds\n",
      "Processed 4000 photos in -2280.400090 seconds\n",
      "Processed 4500 photos in -2573.160216 seconds\n",
      "Processed 5000 photos in -2855.648873 seconds\n",
      "Processed 5500 photos in -3138.568023 seconds\n",
      "Processed 6000 photos in -3421.359722 seconds\n",
      "Processed 6500 photos in -3705.590149 seconds\n",
      "Processed 7000 photos in -3988.211679 seconds\n",
      "Processed 7500 photos in -4271.022012 seconds\n",
      "Processed 8000 photos in -4555.384963 seconds\n",
      "Processed 8500 photos in -4839.588871 seconds\n",
      "Processed 9000 photos in -5122.717281 seconds\n",
      "Processed 9500 photos in -5405.252099 seconds\n",
      "Processed 10000 photos in -5689.548842 seconds\n",
      "Processed 10500 photos in -5971.535603 seconds\n",
      "Processed 11000 photos in -6254.833070 seconds\n",
      "Processed 11500 photos in -6538.222185 seconds\n",
      "Processed 12000 photos in -6820.973929 seconds\n",
      "Processed 12500 photos in -7104.956006 seconds\n",
      "Processed 13000 photos in -7387.889904 seconds\n",
      "Processed 13500 photos in -7671.810659 seconds\n",
      "Processed 14000 photos in -7956.328232 seconds\n",
      "Processed 14500 photos in -8242.220759 seconds\n",
      "Processed 15000 photos in -8525.478494 seconds\n",
      "Processed 15500 photos in -8809.276314 seconds\n",
      "Processed 16000 photos in -9093.842339 seconds\n",
      "Processed 16500 photos in -9376.854263 seconds\n",
      "Processed 17000 photos in -9660.850679 seconds\n",
      "Processed 17500 photos in -9944.924392 seconds\n",
      "Processed 18000 photos in -10228.775516 seconds\n",
      "Processed 18500 photos in -10511.677268 seconds\n",
      "Processed 19000 photos in -10796.719047 seconds\n",
      "Processed 19500 photos in -11079.551636 seconds\n",
      "Processed 20000 photos in -11363.200700 seconds\n"
     ]
    }
   ],
   "source": [
    "valid_features = extract_photo_features(\"../data/split_lists/valid_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir ../data/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/features/train_features.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(train_features, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/features/valid_features.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(valid_features,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20162"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80645"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(range(10), 1000).nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "nbytes not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-eff14dcd3d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: nbytes not found"
     ]
    }
   ],
   "source": [
    "csr_matrix(to_categorical(range(10), 1000)).nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
